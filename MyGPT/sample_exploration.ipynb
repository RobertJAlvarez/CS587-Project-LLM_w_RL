{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655d3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_paragraph_splits(\n",
    "    file_path: str = \"input.txt\",\n",
    "    num_samples: int = 10,\n",
    "    k: int = 5,\n",
    "    eot_token: str = \"<|endoftext|>\",\n",
    "    train_pct: int = 80,\n",
    ") -> tuple[list[list[str]], list[list[str]]]:\n",
    "    \"\"\"\n",
    "    Read the text from `file_path`, split into paragraphs, randomly select\n",
    "    `num_samples` of them, and for each:\n",
    "      - Append the EOT marker to the paragraph text\n",
    "      - Split on whitespace into tokens\n",
    "      - Take the first k tokens into X\n",
    "      - Take all remaining tokens (from k up to and including EOT) into Y\n",
    "\n",
    "    Returns:\n",
    "      X: list of length num_samples; each is a list of k tokens (strings)\n",
    "      Y: list of length num_samples; each is a list of the remaining tokens\n",
    "    \"\"\"\n",
    "    # 1) Load and split into paragraphs (blocks separated by blank lines)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    paragraphs = [p.strip() for p in re.split(r\"\\n\\s*\\n\", raw) if p.strip()]\n",
    "\n",
    "    # 2) Sample paragraphs (without replacement if possible)\n",
    "    if len(paragraphs) >= num_samples:\n",
    "        selected = random.sample(paragraphs, num_samples)\n",
    "    else:\n",
    "        selected = [random.choice(paragraphs) for _ in range(num_samples)]\n",
    "\n",
    "    X: list[list[str]] = []\n",
    "    Y: list[list[str]] = []\n",
    "\n",
    "    for para in selected:\n",
    "        # 3) Append EOT marker\n",
    "        text = f\"{para} {eot_token}\"\n",
    "\n",
    "        # 4) Tokenize on whitespace\n",
    "        tokens = text.split()\n",
    "\n",
    "        # 5) Build prefix and suffix\n",
    "        prefix = tokens[:k]\n",
    "        suffix = tokens[k:]  # all remaining tokens, including the EOT marker\n",
    "\n",
    "        X.append(prefix)\n",
    "        Y.append(suffix)\n",
    "\n",
    "    # Convert sequence of tokens to strings.\n",
    "    X = [\" \".join(x) for x in X]\n",
    "    Y = [\" \".join(y) for y in Y]\n",
    "\n",
    "    Y = [x + \" \" + y for x, y in zip(X, Y)]\n",
    "\n",
    "    # Slip into training and testing.\n",
    "    train_size = int((train_pct / 100) * len(X))\n",
    "\n",
    "    train_prompts = X[:train_size]\n",
    "    train_references = Y[:train_size]\n",
    "    test_prompts = X[train_size:]\n",
    "    test_references = Y[train_size:]\n",
    "\n",
    "    return (train_prompts, train_references), (test_prompts, test_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e751d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sample_paragraph_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cbfac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = “Yes, confound it! Yes,” answered\n",
      "y0 = “Yes, confound it! Yes,” answered Ned Land, “it is superb! I am mad at being obliged to admit it. No one has ever seen anything like it; but the sight may cost us dear. And, if I must say all, I think we are seeing here things which God never intended man to see.” <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "x0 = x[0]\n",
    "y0 = y[0]\n",
    "\n",
    "print(f\"x0 = {x0}\")\n",
    "print(f\"y0 = {y0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf35c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
